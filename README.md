# Computer-Vision
This code is an implementation of transfer learning techniques using the PyTorch library. Transfer learning is a method in machine learning where a model that has been previously trained for one task is used as the foundation (pretrained model) for another similar or related task. In this case, the dataset used is MNIST, which contains images of handwritten digits. Three models are employed: ResNet18, DenseNet121, and Vision Transformer (ViT). The goal of this experiment is to observe how the model's accuracy is influenced by focusing the training on specific layers and to measure the impact of freezing a certain number of layers during training.
